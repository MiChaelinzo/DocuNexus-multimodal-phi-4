# DocuNexus AGI-Agent - Prompt Engineering & Optimization (Azure-Focused)

This notebook is dedicated to the process of prompt engineering for the **DocuNexus AGI-Agent** with an Azure-centric approach, focusing on:

* **Developing effective prompts for Azure OpenAI models:** Testing scenarios such as document analysis, media workflows, and specific tasks (e.g., summarization, comparison, object detection).
* **Exploring prompt variations:** Experimenting with different phrasing, styles, and inclusion of context or few-shot examples to improve the models' accuracy and reliability.
* **Fine-tuning response style:** Achieving concise or detailed outputs, customizing tone, and encouraging clear "thoughts" or reasoning in responses.
* **Evaluating effectiveness:** Assessing prompt performance based on output relevance, accuracy, and user feedback to identify the best approaches.

---

### Example Prompt Engineering Experiments

---

#### **1. Document Summarization Prompt Variations**
```python
from azure.ai.openai import OpenAIClient
from azure.core.credentials import AzureKeyCredential

# Azure OpenAI Client setup
azure_api_key = "YOUR_AZURE_API_KEY"
azure_endpoint = "YOUR_AZURE_ENDPOINT"
client = OpenAIClient(endpoint=azure_endpoint, credential=AzureKeyCredential(azure_api_key))

# Prompts to evaluate summarization quality
prompts = [
    "Summarize this document briefly: [Insert document text here]",
    "Provide a detailed summary of this text, focusing on key points: [Insert document text here]",
    "Extract the main arguments and provide a concise summary: [Insert document text here]"
]

# Run summarization for each prompt
for prompt in prompts:
    response = client.get_chat_completions(
        model="gpt-4",
        messages=[{"role": "system", "content": "You are a helpful summarization assistant."},
                  {"role": "user", "content": prompt}],
        max_tokens=500
    )
    print(f"Prompt: {prompt}\nSummary: {response.choices[0].message['content']}\n")
```

---

#### **2. Few-Shot Prompting for Entity Extraction**
```python
# Few-shot prompt example for extracting entities (e.g., names, dates, locations)
prompt = """
Extract the following entities from the text below:
- Names
- Dates
- Locations

Examples:
1. Input: "John met Sarah in Paris on July 20, 2022."
   Output: {"Names": ["John", "Sarah"], "Dates": ["July 20, 2022"], "Locations": ["Paris"]}

Input text: "[Insert document text here]"
"""

response = client.get_chat_completions(
    model="gpt-4",
    messages=[{"role": "system", "content": "You are an expert in entity extraction."},
              {"role": "user", "content": prompt}],
    max_tokens=500
)
print("Extracted Entities:", response.choices[0].message["content"])
```

---

#### **3. Prompting for Thoughts and Reasoning Clarity**
```python
# Prompt to elicit "thought process" explanations
prompt = """
Analyze the following document and describe the key points. Additionally, explain your thought process for arriving at the conclusions:
[Insert document text here]

Output format:
1. Key Points:
   - [Key Point 1]
   - [Key Point 2]

2. Thought Process:
   [Detailed explanation of reasoning]
"""

response = client.get_chat_completions(
    model="gpt-4",
    messages=[{"role": "system", "content": "You are a document analysis expert."},
              {"role": "user", "content": prompt}],
    max_tokens=1000
)
print("Response with Reasoning:\n", response.choices[0].message["content"])
```

---

### **Prompt Optimization Results & Best Practices**
This section summarizes the outcomes of the experiments conducted above:

#### Best Practices for Prompt Engineering:
1. **Be Explicit in Instructions:**
   - Specify the task clearly (e.g., "Summarize briefly" vs. "Extract arguments and summarize concisely").
   - Use formats and examples to guide the AI’s reasoning.

2. **Leverage Few-Shot Examples:**
   - Include examples to improve performance on complex tasks like entity extraction or custom formatting.

3. **Encourage "Thoughts" and Reasoning:**
   - Request detailed explanations of the model’s reasoning process to improve transparency and usability.

4. **Parameter Tuning:**
   - Adjust generation parameters:
     - Use `temperature=0.3` for deterministic tasks like summarization.
     - Use `temperature=0.7+` for creative outputs like story generation.

#### Prompt Performance Metrics:
- **Accuracy:** Assessed based on how closely responses matched user expectations.
- **Relevance:** Evaluated by the presence of appropriate and informative details.
- **User Satisfaction:** Collected through qualitative feedback on outputs.

### **Conclusion**
By refining prompt structures and leveraging Azure OpenAI’s powerful models, DocuNexus AGI-Agent achieves significant improvements in accuracy, efficiency, and reliability across various tasks. The use of explicit instructions, few-shot prompting, and reasoning transparency ensures optimal user satisfaction and high-quality responses.

